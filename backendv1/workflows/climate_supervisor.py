"""
Climate Economy Assistant - Main Supervisor Workflow

Following rule #18: Step-by-step planning - extracted core orchestration from climate_supervisor_workflow.py
Following rule #12: Complete code verification with clean LangGraph architecture
Following rule #15: Include comprehensive error handling for workflow operations

This is the main LangGraph workflow orchestrator - integrated with Pendo Supervisor.
Now enhanced with conversational incremental updates and human steering.
Location: backendv1/workflows/climate_supervisor.py
"""

import asyncio
import sys
import os
from typing import Dict, Any, List, Optional, Literal, TypedDict, Annotated, Union
from datetime import datetime

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, BaseMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.types import Command

# Add interrupt import with fallback
try:
    from langgraph.types import interrupt
except ImportError:
    # Fallback for environments where interrupt is not available
    def interrupt(context: Dict[str, Any]) -> str:
        """Fallback interrupt function for testing environments"""
        return context.get("question", "Please provide input")

from backendv1.utils.logger import setup_logger
from backendv1.config.settings import get_settings
from backendv1.agents.base.agent_base import AgentContext
from backendv1.workflows.human_steering import HumanSteering

# Setup logging and configuration
logger = setup_logger("climate_supervisor")
settings = get_settings()

# Import agent classes
try:
    from backendv1.agents.pendo.agent import PendoAgent
    from backendv1.agents.alex.agent import AlexAgent
    from backendv1.agents.lauren.agent import LaurenAgent
    from backendv1.agents.mai.agent import MaiAgent
    from backendv1.agents.marcus.agent import MarcusAgent
    from backendv1.agents.miguel.agent import MiguelAgent
    from backendv1.agents.liv.agent import LivAgent
    from backendv1.agents.jasmine.agent import JasmineAgent
except ImportError as e:
    logger.warning(f"Could not import some agents: {e}")


class ClimateAgentState(TypedDict):
    """State for climate agent workflow"""

    messages: List[BaseMessage]
    needs_human_review: bool
    human_steering_context: Optional[Dict[str, Any]]
    workflow_state: str
    human_steering_count: int
    waiting_for_input: bool
    step_count: int  # Track total steps in workflow
    incremental_findings: List[Dict[str, Any]]  # Track findings as we go
    conversation_history: List[Dict[str, Any]]  # Track conversation history
    user_id: Optional[str]  # Track user ID for context
    session_id: Optional[str]  # Track session ID for context
    conversation_complete: bool  # Flag to indicate conversation completion


async def safe_state_update(state: ClimateAgentState, updates: Dict[str, Any]) -> Dict[str, Any]:
    """Safely update state with error handling - TypedDict compatible"""
    try:
        # For TypedDict, we return the updates directly as LangGraph handles merging
        return updates
    except Exception as e:
        logger.error(f"Error updating state: {e}")
        return {}


class ClimateSupervisorWorkflow:
    """
    Enhanced Climate Supervisor with conversational incremental updates

    Key improvements:
    - Incremental findings with human steering
    - Partner-focused recommendations
    - Conversational flow with reduced wait times
    - 80%+ confidence threshold for applications
    - LangGraph chat interface compatible
    """

    def __init__(self):
        """Initialize enhanced climate supervisor"""
        logger.info("Initializing enhanced climate supervisor with conversational flow")
        self.agents = {}
        self.pendo_supervisor = None
        self.human_steering = HumanSteering()  # Initialize intelligent human steering
        self._initialize_agents()
        self.graph = self._create_enhanced_workflow_graph()

    def _initialize_agents(self):
        """Initialize all climate agents"""
        try:
            # Initialize Pendo as the intelligent router
            self.pendo_supervisor = PendoAgent("Pendo", "supervisor")

            # Initialize specialist agents
            self.agents = {
                "alex": AlexAgent("Alex", "empathy_specialist"),
                "lauren": LaurenAgent("Lauren", "climate_career_specialist"),
                "mai": MaiAgent("Mai", "resume_specialist"),
                "marcus": MarcusAgent("Marcus", "job_market_analyst"),
                "miguel": MiguelAgent("Miguel", "skills_development_specialist"),
                "liv": LivAgent("Liv", "networking_specialist"),
                "jasmine": JasmineAgent("Jasmine", "interview_specialist"),
            }

            logger.info("âœ… All climate agents initialized successfully")

        except Exception as e:
            logger.error(f"Error initializing agents: {e}")
            self.agents = {}

    def _create_enhanced_workflow_graph(self) -> StateGraph:
        """Create enhanced workflow graph with conversational flow"""
        workflow = StateGraph(ClimateAgentState)

        # Enhanced nodes for conversational flow
        workflow.add_node("initial_discovery", self._initial_discovery)
        workflow.add_node("incremental_analysis", self._incremental_analysis)
        workflow.add_node("human_steering_point", self._human_steering_point)
        workflow.add_node("partner_matching", self._partner_matching)
        workflow.add_node("confidence_assessment", self._confidence_assessment)
        workflow.add_node("application_guidance", self._application_guidance)
        workflow.add_node("conversation_continuation", self._conversation_continuation)

        # Set the entrypoint - START edge to initial_discovery
        workflow.add_edge(START, "initial_discovery")

        # Add routing logic
        workflow.add_conditional_edges(
            "initial_discovery",
            self._route_initial_discovery,
            {
                "analysis": "incremental_analysis",
                "human_review": "human_steering_point",
                "END": END,
            },
        )

        workflow.add_conditional_edges(
            "incremental_analysis",
            self._route_after_analysis,
            {
                "confidence_assessment": "confidence_assessment",
                "partner_matching": "partner_matching",
                "human_review": "human_steering_point",
                "END": END,
            },
        )

        workflow.add_conditional_edges(
            "confidence_assessment",
            self._route_after_confidence,
            {
                "application_guidance": "application_guidance",
                "partner_matching": "partner_matching",
                "conversation_continuation": "conversation_continuation",
                "END": END,
            },
        )

        workflow.add_conditional_edges(
            "application_guidance",
            self._route_after_application,
            {"conversation_continuation": "conversation_continuation", "END": END},
        )

        workflow.add_conditional_edges(
            "partner_matching",
            self._route_after_analysis,
            {
                "confidence_assessment": "confidence_assessment",
                "human_review": "human_steering_point",
                "END": END,
            },
        )

        workflow.add_conditional_edges(
            "human_steering_point",
            self._route_conversation_flow,
            {
                "incremental_analysis": "incremental_analysis",
                "human_steering_point": "human_steering_point",
                "END": END,
            },
        )

        workflow.add_conditional_edges(
            "conversation_continuation",
            self._route_conversation_flow,
            {
                "incremental_analysis": "incremental_analysis",
                "human_steering_point": "human_steering_point",
                "END": END,
            },
        )

        # LangGraph API handles persistence automatically - no custom checkpointer needed
        return workflow.compile()

    async def _initial_discovery(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Initial discovery with immediate small finding"""
        try:
            logger.info("ðŸ” Starting initial discovery with immediate insights")

            # Get latest user message from messages
            latest_message = ""
            if state.get("messages"):
                latest_message = (
                    state["messages"][-1].content
                    if hasattr(state["messages"][-1], "content")
                    else str(state["messages"][-1])
                )

            # Quick initial analysis
            context = AgentContext(
                user_id=state.get("user_id", "anonymous"),
                session_id=state.get("session_id", "discovery_session"),
                conversation_history=state.get("conversation_history", []),
            )

            # Check for simple greetings first
            simple_greetings = ["hi", "hello", "hey", "sup", "yo", "howdy"]
            if latest_message.lower().strip() in simple_greetings:
                # Generate immediate friendly response for greetings
                greeting_response = AIMessage(
                    content="Hi there! I'm here to help you explore climate career opportunities. What interests you most?"
                )
                
                logger.info(f"Generated simple greeting response for: '{latest_message}'")
                
                return {
                    "messages": [greeting_response],
                    "workflow_state": "completed",
                    "conversation_complete": True,  # Allow conversation to end here
                    "incremental_findings": [{
                        "type": "greeting",
                        "message": "User initiated conversation with greeting",
                        "timestamp": datetime.utcnow().isoformat(),
                    }]
                }

            # Use Pendo for intelligent initial routing for complex messages
            if self.pendo_supervisor:
                initial_response = await self.pendo_supervisor.process_message(
                    latest_message, context
                )

                # Extract immediate finding
                immediate_finding = {
                    "type": "initial_discovery",
                    "insight": f"I can see you're interested in {self._extract_interest_area(latest_message)}",
                    "confidence": 0.7,
                    "next_step": "Let me analyze this further to give you specific guidance",
                    "timestamp": datetime.utcnow().isoformat(),
                }

                # Create AI response message
                ai_response = AIMessage(content=initial_response.content)

                return {
                    "messages": [ai_response],
                    "workflow_state": "analysis",
                    "current_agent": "pendo",
                    "incremental_findings": state.get("incremental_findings", [])
                    + [immediate_finding],
                    "human_steering_context": {
                        "immediate_insight": immediate_finding["insight"],
                        "suggested_next": "Would you like me to analyze your background for specific climate career opportunities?",
                    },
                }

            # Fallback response
            fallback_response = AIMessage(
                content="Welcome! I'm here to help you explore climate career opportunities. Let me analyze your needs."
            )

            return {
                "messages": [fallback_response],
                "workflow_state": "analysis",
                "needs_human_review": True,
            }

        except Exception as e:
            logger.error(f"Error in initial discovery: {e}")
            error_response = AIMessage(
                content="I'm experiencing a technical issue. Let me connect you with our team for support."
            )
            return {
                "messages": [error_response],
                "workflow_state": "error",
                "needs_human_review": True,
            }

    async def _incremental_analysis(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Provide incremental analysis with small findings"""
        try:
            logger.info("ðŸ“Š Conducting incremental analysis")

            # Determine which agent should provide the next insight
            analysis_agent = self._select_analysis_agent(state)

            if analysis_agent and analysis_agent in self.agents:
                agent = self.agents[analysis_agent]

                context = AgentContext(
                    user_id=state.get("user_id", "anonymous"),
                    session_id=state.get("session_id", "analysis_session"),
                    conversation_history=state.get("conversation_history", []),
                    metadata={
                        "workflow_stage": "incremental_analysis",
                        "previous_findings": state.get("incremental_findings", []),
                    },
                )

                # Get focused analysis from specialist
                latest_message = (
                    state["messages"][-1].content if state.get("messages") else "Analyze my profile"
                )
                agent_response = await agent.process_message(latest_message, context)

                # Create incremental finding
                incremental_finding = {
                    "type": "specialist_analysis",
                    "agent": analysis_agent,
                    "insight": self._extract_key_insight(agent_response.content),
                    "confidence": agent_response.confidence_score,
                    "sources": agent_response.sources,
                    "next_actions": agent_response.next_actions[:2],  # Limit to 2 actions
                    "timestamp": datetime.utcnow().isoformat(),
                }

                # Create AI response message
                ai_response = AIMessage(content=agent_response.content)

                return {
                    "messages": [ai_response],
                    "current_agent": analysis_agent,
                    "incremental_findings": state.get("incremental_findings", [])
                    + [incremental_finding],
                    "human_steering_context": {
                        "latest_insight": incremental_finding["insight"],
                        "confidence": incremental_finding["confidence"],
                        "suggested_next": f"Based on this analysis, would you like me to {incremental_finding['next_actions'][0] if incremental_finding['next_actions'] else 'continue exploring opportunities'}?",
                    },
                }

            # Fallback response
            fallback_response = AIMessage(
                content="I need your input to provide the most relevant guidance. What specific aspect of climate careers interests you most?"
            )

            return {
                "messages": [fallback_response],
                "needs_human_review": True,
                "human_steering_context": {
                    "message": "I need your input to provide the most relevant guidance. What specific aspect of climate careers interests you most?"
                },
            }

        except Exception as e:
            logger.error(f"Error in incremental analysis: {e}")
            error_response = AIMessage(
                content="I encountered an issue during analysis. Let me help you in a different way."
            )
            return {"messages": [error_response], "needs_human_review": True}

    async def _human_steering_point(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Enhanced human steering with comprehensive context and guidance"""
        try:
            logger.info("ðŸŽ¯ Enhanced human steering point with comprehensive guidance")

            # Initialize steering count if not present
            steering_count = state.get("human_steering_count", 0)

            # Check if we've exceeded steering attempts
            if steering_count >= 3:
                logger.warning("Max steering attempts reached, providing summary")
                return await self._create_completion_summary(state)

            # Check if we have a human message to process
            has_human_input = False
            latest_human_message = None
            if state.get("messages"):
                for msg in reversed(state["messages"]):
                    if isinstance(msg, HumanMessage):
                        has_human_input = True
                        latest_human_message = msg
                        break

            # If no human input yet, provide comprehensive guidance and wait
            if not has_human_input:
                return await self._provide_comprehensive_guidance(state, steering_count)

            # If we have human input, process it and move forward
            if latest_human_message:
                return await self._process_human_input(state, latest_human_message, steering_count)

            # Fallback response
            return await self._create_fallback_response(state, steering_count)

        except Exception as e:
            logger.error(f"Error in enhanced human steering: {e}")
            return await self._create_error_response(state)

    async def _provide_comprehensive_guidance(
        self, state: ClimateAgentState, steering_count: int
    ) -> Dict[str, Any]:
        """Provide comprehensive guidance with database info, tools, and examples"""

        # Get current findings and progress
        current_findings = state.get("incremental_findings", [])
        user_journey_stage = state.get("user_journey_stage", "discovery")

        # Get comprehensive context
        guidance_context = await self._build_comprehensive_context(state)

        # Build stage-specific guidance message
        guidance_message = self._build_guidance_message(
            user_journey_stage, current_findings, guidance_context, steering_count
        )

        # Create comprehensive steering context for interrupt
        steering_context = {
            "type": "comprehensive_guidance",
            "stage": user_journey_stage,
            "guidance_provided": True,
            "database_summary": guidance_context["database_info"],
            "agent_capabilities": guidance_context["agent_tools"],
            "suggested_actions": guidance_context["suggested_actions"],
            "example_inputs": guidance_context["example_inputs"],
            "current_progress": {
                "findings_count": len(current_findings),
                "confidence_level": self._calculate_overall_confidence(state),
                "stage": user_journey_stage,
            },
            "question": self._get_stage_question(user_journey_stage),
            "steering_attempt": steering_count + 1,
        }

        # Use interrupt with comprehensive context
        try:
            user_response = interrupt(steering_context)

            # Process the response
            return await self._process_interrupt_response(user_response, state, steering_count)

        except Exception as interrupt_error:
            # Fallback for testing environments
            logger.warning(f"Interrupt not available in test context: {interrupt_error}")

            ai_response = AIMessage(content=guidance_message)
            return {
                "messages": [ai_response],
                "needs_human_review": True,
                "human_steering_context": steering_context,
                "workflow_state": "human_guided",
                "human_steering_count": steering_count + 1,
                "waiting_for_input": True,
                "user_guidance_provided": True,
            }

    def _build_guidance_message(
        self, stage: str, findings: List[Dict], context: Dict[str, Any], steering_count: int
    ) -> str:
        """Build comprehensive guidance message based on stage and context"""

        db_info = context["database_info"]
        tools = context["agent_tools"]
        examples = context["example_inputs"]
        actions = context["suggested_actions"]

        if stage == "discovery":
            return f"""ðŸŽ¯ **Welcome to Your Climate Career Discovery Journey!**

I'm here to help you explore climate career opportunities. Let me show you what's available and how I can assist you.

## ðŸ” **What I Can Help You With:**

**ðŸ“Š Database Resources Available:**
â€¢ **{db_info['total_jobs']:,} climate jobs** across {db_info['job_categories']} categories
â€¢ **{db_info['total_organizations']} partner organizations** ready to hire
â€¢ **{db_info['skills_frameworks']} skills frameworks** for career development
â€¢ **{db_info['salary_data_points']:,} salary data points** for compensation insights

**ðŸ› ï¸ My Available Tools & Capabilities:**
{self._format_tools_list(tools)}

**ðŸŒŸ Suggested Next Steps:**
{self._format_suggested_actions(actions)}

**ðŸ’¡ Example Questions You Can Ask:**
{self._format_example_inputs(examples)}

**ðŸ“ˆ Current Progress:** {len(findings)} insights gathered | Confidence: {self._calculate_overall_confidence_percentage(findings)}%

**What would you like to explore first?** Just type your question or choose one of the suggested options above!"""

        elif stage == "strategy":
            return f"""ðŸŽ¯ **Let's Build Your Climate Career Strategy!**

Based on our discovery, I can now help you create a strategic plan. Here's what I can do:

## ðŸ“Š **Your Current Profile Analysis:**
{self._format_findings_summary(findings)}

## ðŸ› ï¸ **Strategic Planning Tools Available:**
{self._format_tools_list(tools)}

**ðŸŒŸ Strategic Options for You:**
{self._format_suggested_actions(actions)}

**ðŸ’¡ Strategic Questions You Can Ask:**
{self._format_example_inputs(examples)}

**ðŸ“ˆ Current Confidence:** {self._calculate_overall_confidence_percentage(findings)}% | Ready for strategic planning

**Which strategic direction interests you most?**"""

        elif stage == "action_planning":
            return f"""ðŸŽ¯ **Time to Take Action on Your Climate Career!**

You're ready to move from planning to execution. Here's how I can support your next steps:

## ðŸ“Š **Your Personalized Action Plan Foundation:**
{self._format_findings_summary(findings)}

## ðŸ› ï¸ **Action-Oriented Tools & Support:**
{self._format_tools_list(tools)}

**ðŸŒŸ Immediate Action Steps:**
{self._format_suggested_actions(actions)}

**ðŸ’¡ Action-Focused Questions:**
{self._format_example_inputs(examples)}

**ðŸ“ˆ Success Probability:** {self._calculate_overall_confidence_percentage(findings)}% based on your profile match

**What's your priority action for this week?**"""

        else:
            # General guidance
            return f"""ðŸŽ¯ **Your Climate Career Assistant is Ready!**

I'm here to help you navigate climate career opportunities. Here's everything I can do for you:

## ðŸ” **Complete Resource Overview:**

**ðŸ“Š Database Access:**
â€¢ **{db_info['total_jobs']:,} active climate job postings**
â€¢ **{db_info['total_organizations']} partner organizations**
â€¢ **{db_info['skills_frameworks']} skills development frameworks**
â€¢ **{db_info['salary_data_points']:,} salary data points**

**ðŸ› ï¸ Full Capability Suite:**
{self._format_tools_list(tools)}

**ðŸŒŸ Popular Starting Points:**
{self._format_suggested_actions(actions)}

**ðŸ’¡ You Can Ask Me:**
{self._format_example_inputs(examples)}

**ðŸ“ˆ Current Status:** {len(findings)} insights gathered | Ready to assist with any climate career need

**How can I help you advance your climate career today?**"""

    async def _build_comprehensive_context(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Build comprehensive context including database info, tools, and examples"""

        # Database information
        database_info = {
            "total_jobs": 15000,
            "job_categories": 25,
            "total_organizations": 500,
            "skills_frameworks": 12,
            "salary_data_points": 50000,
            "location_coverage": "Global with focus on US, EU, Canada",
        }

        # Agent tools and capabilities
        agent_tools = [
            {
                "name": "Job Search & Matching",
                "description": "Find climate jobs based on skills, location, and preferences",
                "examples": [
                    "Find renewable energy jobs in California",
                    "Search for remote climate policy roles",
                ],
            },
            {
                "name": "Skills Assessment",
                "description": "Analyze current skills and identify development needs",
                "examples": [
                    "Assess my background for climate finance",
                    "What skills do I need for sustainability consulting?",
                ],
            },
            {
                "name": "Partner Network Access",
                "description": "Connect with 50+ climate organizations for opportunities",
                "examples": [
                    "Introduce me to clean energy startups",
                    "Connect me with climate nonprofits",
                ],
            },
            {
                "name": "Career Pathway Analysis",
                "description": "Map career transitions and progression routes",
                "examples": [
                    "How do I transition from tech to climate tech?",
                    "Show me climate finance career paths",
                ],
            },
            {
                "name": "Market Analysis",
                "description": "Salary insights and market trends",
                "examples": [
                    "What do climate data scientists earn?",
                    "Which climate sectors are growing fastest?",
                ],
            },
            {
                "name": "Application Support",
                "description": "Resume, cover letter, and interview preparation",
                "examples": [
                    "Review my resume for climate roles",
                    "Prepare me for a sustainability interview",
                ],
            },
        ]

        # Stage-specific examples and actions
        stage = state.get("user_journey_stage", "discovery")

        if stage == "discovery":
            example_inputs = [
                "I have a background in engineering - what climate roles are available?",
                "Show me remote climate policy jobs",
                "What skills do I need for clean energy project management?",
                "Help me transition from finance to climate finance",
                "I want to work for a climate nonprofit",
            ]
            suggested_actions = [
                {
                    "action": "Analyze my background",
                    "description": "Get personalized climate career recommendations",
                },
                {
                    "action": "Search climate jobs",
                    "description": "Find opportunities matching your interests",
                },
                {
                    "action": "Explore career pathways",
                    "description": "See different routes into climate work",
                },
                {
                    "action": "Assess my skills",
                    "description": "Identify strengths and development areas",
                },
                {
                    "action": "Connect with network",
                    "description": "Access our partner organizations",
                },
            ]
        elif stage == "strategy":
            example_inputs = [
                "Create a career transition plan from consulting to climate work",
                "What's the fastest path to renewable energy careers?",
                "Compare climate finance vs clean energy opportunities",
                "Should I target startups or established companies?",
                "Build my skills development roadmap",
            ]
            suggested_actions = [
                {
                    "action": "Create transition plan",
                    "description": "Step-by-step roadmap to climate careers",
                },
                {
                    "action": "Compare sectors",
                    "description": "Evaluate different climate industry options",
                },
                {
                    "action": "Build skills roadmap",
                    "description": "Prioritized learning and development plan",
                },
                {
                    "action": "Analyze market trends",
                    "description": "Understand growth areas and opportunities",
                },
                {
                    "action": "Set timeline goals",
                    "description": "Create realistic milestones and deadlines",
                },
            ]
        elif stage == "action_planning":
            example_inputs = [
                "Help me apply to specific climate jobs this week",
                "Connect me with Tesla's sustainability team",
                "Review my resume for climate roles",
                "Prepare me for a clean energy interview",
                "Create my networking strategy for climate professionals",
            ]
            suggested_actions = [
                {
                    "action": "Apply to jobs",
                    "description": "Target specific opportunities with support",
                },
                {
                    "action": "Get introductions",
                    "description": "Connect with relevant organizations",
                },
                {
                    "action": "Optimize applications",
                    "description": "Improve resume and cover letters",
                },
                {
                    "action": "Prepare for interviews",
                    "description": "Practice climate-specific questions",
                },
                {"action": "Build network", "description": "Strategic relationship building"},
            ]
        else:
            example_inputs = [
                "Analyze my background for climate careers",
                "Show me climate jobs in my area",
                "What skills do I need for sustainability roles?",
                "Create my climate career transition plan",
                "Connect me with climate professionals",
            ]
            suggested_actions = [
                {"action": "Explore opportunities", "description": "Find climate career options"},
                {"action": "Assess readiness", "description": "Evaluate your preparation level"},
                {"action": "Plan transition", "description": "Create strategic roadmap"},
                {"action": "Build skills", "description": "Develop climate-relevant capabilities"},
                {"action": "Network", "description": "Connect with industry professionals"},
            ]

        return {
            "database_info": database_info,
            "agent_tools": agent_tools,
            "example_inputs": example_inputs,
            "suggested_actions": suggested_actions,
        }

    def _format_tools_list(self, tools: List[Dict[str, Any]]) -> str:
        """Format tools list for display"""
        formatted = []
        for tool in tools:
            formatted.append(f"â€¢ **{tool['name']}**: {tool['description']}")
        return "\n".join(formatted)

    def _format_suggested_actions(self, actions: List[Dict[str, str]]) -> str:
        """Format suggested actions for display"""
        formatted = []
        for i, action in enumerate(actions, 1):
            formatted.append(f"{i}. **\"{action['action']}\"** - {action['description']}")
        return "\n".join(formatted)

    def _format_example_inputs(self, examples: List[str]) -> str:
        """Format example inputs for display"""
        formatted = []
        for example in examples:
            formatted.append(f'â€¢ "{example}"')
        return "\n".join(formatted)

    def _get_stage_question(self, stage: str) -> str:
        """Get appropriate question for the current stage"""
        questions = {
            "discovery": "What aspect of climate careers would you like to explore first?",
            "strategy": "Which strategic direction interests you most?",
            "action_planning": "What's your priority action for this week?",
            "general": "How can I help you advance your climate career today?",
        }
        return questions.get(stage, questions["general"])

    def _calculate_overall_confidence_percentage(self, findings: List[Dict]) -> int:
        """Calculate confidence as percentage for display"""
        return int(min(90, len(findings) * 20 + 10))

    async def _process_interrupt_response(
        self,
        user_response: Union[str, Dict[str, Any]],
        state: ClimateAgentState,
        steering_count: int,
    ) -> Dict[str, Any]:
        """Process user response from interrupt"""

        try:
            # Handle different response formats
            if isinstance(user_response, str):
                response_text = user_response
            elif isinstance(user_response, dict):
                response_text = user_response.get("text", str(user_response))
            else:
                response_text = str(user_response)

            # Create acknowledgment message
            acknowledgment = AIMessage(
                content=f"I understand you want to {response_text}. Let me help you with that!"
            )

            # Determine next workflow state based on response
            next_state = self._determine_workflow_state(response_text)

            return {
                "messages": [acknowledgment],
                "needs_human_review": False,
                "workflow_state": next_state,
                "human_steering_count": steering_count + 1,
                "waiting_for_input": False,
                "user_input_processed": True,
                "last_user_response": response_text,
            }

        except Exception as e:
            logger.error(f"Error processing interrupt response: {e}")
            return await self._create_error_response(state)

    def _determine_workflow_state(self, response_text: str) -> str:
        """Determine next workflow state based on user response"""

        response_lower = response_text.lower()

        # Keywords that indicate different workflow paths
        if any(
            keyword in response_lower for keyword in ["search", "find", "jobs", "opportunities"]
        ):
            return "partner_matching"
        elif any(
            keyword in response_lower for keyword in ["analyze", "assess", "background", "skills"]
        ):
            return "incremental_analysis"
        elif any(
            keyword in response_lower for keyword in ["plan", "strategy", "roadmap", "transition"]
        ):
            return "confidence_assessment"
        elif any(
            keyword in response_lower for keyword in ["apply", "connect", "introduction", "network"]
        ):
            return "application_guidance"
        else:
            return "incremental_analysis"  # Default to analysis

    async def _create_completion_summary(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Create completion summary when max steering attempts reached"""

        current_findings = state.get("incremental_findings", [])
        confidence_level = self._calculate_overall_confidence(state)

        summary_message = f"""ðŸ“Š **Summary of Our Climate Career Discussion**

Based on our conversation, here's what we've learned:

**ðŸ” Key Insights:**
{self._format_findings_summary(current_findings)}

**ðŸ“ˆ Overall Confidence:** {confidence_level:.1%}

**ðŸš€ Next Steps:**
1. Review the opportunities we've identified
2. Consider the skill development recommendations
3. Connect with our partner organizations

Would you like to:
â€¢ Start a new conversation to explore different options
â€¢ Get more details about any specific opportunity
â€¢ Connect with our climate career specialists

Let me know how I can help you further!"""

        return {
            "messages": [AIMessage(content=summary_message)],
            "needs_human_review": False,
            "workflow_state": "complete",
            "conversation_complete": True,
            "waiting_for_input": False,
        }

    async def _create_fallback_response(
        self, state: ClimateAgentState, steering_count: int
    ) -> Dict[str, Any]:
        """Create fallback response"""

        fallback_message = "I understand. Let me help you explore climate career opportunities."

        return {
            "messages": [AIMessage(content=fallback_message)],
            "needs_human_review": False,
            "workflow_state": "incremental_analysis",
            "human_steering_count": steering_count + 1,
            "waiting_for_input": False,
        }

    async def _create_error_response(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Create error response"""

        error_message = "Let me help you decide on the next steps. What aspect of climate careers would you like to explore?"

        return {
            "messages": [AIMessage(content=error_message)],
            "needs_human_review": True,
            "waiting_for_input": True,
        }

    async def _partner_matching(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Match with partners from Supabase database"""
        try:
            logger.info("ðŸ¤ Matching with climate partners from database")

            # Use Marcus for market insights and Lauren for partner matching
            if "marcus" in self.agents and "lauren" in self.agents:
                context = AgentContext(
                    user_id=state.get("user_id", "anonymous"),
                    session_id=state.get("session_id", "partner_session"),
                    conversation_history=state.get("conversation_history", []),
                    metadata={
                        "workflow_stage": "partner_matching",
                        "user_profile": state.get("user_profile", {}),
                        "findings": state.get("incremental_findings", []),
                    },
                )

                # Get partner matches (simulated - would query Supabase in production)
                partner_matches = await self._query_partner_database(state)

                # Create partner finding
                partner_finding = {
                    "type": "partner_matches",
                    "matches": partner_matches,
                    "match_confidence": self._calculate_match_confidence(partner_matches),
                    "sources": ["CEA Partner Database", "Climate Organization Network"],
                    "timestamp": datetime.utcnow().isoformat(),
                }

                # Create response message
                if partner_matches:
                    top_match = partner_matches[0]
                    match_message = f"""ðŸŽ¯ **Perfect Climate Career Matches Found!**

I found {len(partner_matches)} excellent opportunities in our partner network:

**ðŸŒŸ Top Match:**
â€¢ **{top_match['organization']}** - {top_match['role']}
â€¢ **Location:** {top_match['location']}
â€¢ **Salary:** {top_match['salary_range']}
â€¢ **Match Score:** {top_match['match_score']:.0%}

**ðŸš€ Next Steps:**
â€¢ Apply directly at their career page
â€¢ We'll connect you with the hiring manager
â€¢ Get interview preparation support

Ready to move forward with this opportunity?"""
                else:
                    match_message = "I'm still searching our partner database for the best matches. Let me continue analyzing your profile."

                ai_response = AIMessage(content=match_message)

                return {
                    "messages": [ai_response],
                    "partner_matches": partner_matches,
                    "incremental_findings": state.get("incremental_findings", [])
                    + [partner_finding],
                    "workflow_state": "partner_matched",
                }

            # Fallback response
            fallback_response = AIMessage(
                content="Let me search our partner database for opportunities that match your background."
            )
            return {"messages": [fallback_response], "needs_human_review": True}

        except Exception as e:
            logger.error(f"Error in partner matching: {e}")
            error_response = AIMessage(
                content="I'm having trouble accessing our partner database. Let me help you in another way."
            )
            return {"messages": [error_response], "needs_human_review": True}

    async def _confidence_assessment(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Assess confidence for application recommendations"""
        try:
            logger.info("ðŸ“ˆ Assessing confidence for application guidance")

            overall_confidence = self._calculate_overall_confidence(state)

            confidence_finding = {
                "type": "confidence_assessment",
                "overall_confidence": overall_confidence,
                "threshold_met": overall_confidence >= state.confidence_threshold,
                "recommendation": (
                    "apply"
                    if overall_confidence >= state.confidence_threshold
                    else "develop_further"
                ),
                "timestamp": datetime.utcnow().isoformat(),
            }

            state.incremental_findings.append(confidence_finding)

            return await safe_state_update(
                state,
                {
                    "incremental_findings": state.incremental_findings,
                    "workflow_state": "confidence_assessed",
                },
            )

        except Exception as e:
            logger.error(f"Error in confidence assessment: {e}")
            return await safe_state_update(state, {"needs_human_review": True})

    async def _application_guidance(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Provide application guidance with partner connections"""
        try:
            logger.info("ðŸŽ¯ Providing application guidance with partner connections")

            if state.partner_matches:
                top_match = state.partner_matches[0]

                application_guidance = {
                    "type": "application_guidance",
                    "recommended_action": "apply_now",
                    "partner_info": {
                        "organization": top_match.get("organization", "Climate Partner"),
                        "role": top_match.get("role", "Climate Professional"),
                        "application_url": top_match.get(
                            "career_page_url", "https://partner-careers.com"
                        ),
                        "contact_person": top_match.get("contact", "Hiring Manager"),
                    },
                    "confidence": self._calculate_overall_confidence(state),
                    "next_steps": [
                        f"Apply directly at {top_match.get('career_page_url', 'partner website')}",
                        "We'll connect you with the hiring manager for an interview",
                        "Continue developing skills for future opportunities",
                    ],
                    "timestamp": datetime.utcnow().isoformat(),
                }

                state.incremental_findings.append(application_guidance)

                return await safe_state_update(
                    state,
                    {
                        "incremental_findings": state.incremental_findings,
                        "workflow_state": "application_ready",
                        "conversation_complete": True,
                    },
                )

            return await safe_state_update(state, {"needs_human_review": True})

        except Exception as e:
            logger.error(f"Error in application guidance: {e}")
            return await safe_state_update(state, {"needs_human_review": True})

    async def _conversation_continuation(self, state: ClimateAgentState) -> Dict[str, Any]:
        """Continue conversation with next steps"""
        try:
            logger.info("ðŸ’¬ Continuing conversation with next steps")

            continuation_options = {
                "type": "conversation_continuation",
                "options": [
                    "Explore more opportunities in our partner network",
                    "Get additional skill development recommendations",
                    "Connect with climate professionals in your area",
                    "Receive interview preparation guidance",
                ],
                "current_progress": len(state.incremental_findings),
                "confidence_level": self._calculate_overall_confidence(state),
                "timestamp": datetime.utcnow().isoformat(),
            }

            state.incremental_findings.append(continuation_options)

            return await safe_state_update(
                state,
                {
                    "incremental_findings": state.incremental_findings,
                    "needs_human_review": True,
                    "human_steering_context": {
                        "message": "What would you like to explore next?",
                        "options": continuation_options["options"],
                    },
                },
            )

        except Exception as e:
            logger.error(f"Error in conversation continuation: {e}")
            return await safe_state_update(state, {"conversation_complete": True})

    # Helper methods
    def _extract_interest_area(self, message: str) -> str:
        """Extract interest area from user message"""
        climate_areas = [
            "renewable energy",
            "sustainability",
            "climate tech",
            "environmental",
            "green jobs",
            "carbon",
            "solar",
            "wind",
        ]
        message_lower = message.lower()

        for area in climate_areas:
            if area in message_lower:
                return area

        return "climate careers"

    def _select_analysis_agent(self, state: ClimateAgentState) -> str:
        """Select appropriate agent for analysis"""
        incremental_findings = state.get("incremental_findings", [])
        if not incremental_findings:
            return "mai"  # Start with resume analysis

        last_finding = incremental_findings[-1]

        if last_finding.get("type") == "initial_discovery":
            return "mai"
        elif last_finding.get("agent") == "mai":
            return "lauren"
        elif last_finding.get("agent") == "lauren":
            return "marcus"
        else:
            return "lauren"

    def _extract_key_insight(self, content: str) -> str:
        """Extract key insight from agent response"""
        # Simple extraction - in production, this would be more sophisticated
        sentences = content.split(".")[:2]
        return ". ".join(sentences) + "." if sentences else content[:100] + "..."

    def _get_available_tools_summary(self) -> Dict[str, str]:
        """Get summary of available tools"""
        return {
            "resume_analysis": "AI-powered resume optimization and skills extraction",
            "partner_matching": "Direct connections with 50+ climate organizations",
            "market_insights": "Real-time climate job market data and trends",
            "skill_development": "Personalized learning paths for climate careers",
            "networking": "Climate professional network and mentorship",
            "interview_prep": "Climate-specific interview preparation and practice",
        }

    def _calculate_overall_confidence(self, state: ClimateAgentState) -> float:
        """Calculate overall confidence from findings"""
        incremental_findings = state.get("incremental_findings", [])
        if not incremental_findings:
            return 0.5

        confidences = [f.get("confidence", 0.5) for f in incremental_findings if "confidence" in f]
        return sum(confidences) / len(confidences) if confidences else 0.5

    async def _query_partner_database(self, state: ClimateAgentState) -> List[Dict[str, Any]]:
        """Query partner database for matches (simulated)"""
        # In production, this would query Supabase
        return [
            {
                "organization": "Massachusetts Clean Energy Center",
                "role": "Climate Data Analyst",
                "match_score": 0.92,
                "career_page_url": "https://masscec.com/careers",
                "contact": "Sarah Johnson, Talent Acquisition",
                "location": "Boston, MA",
                "salary_range": "$70,000-$85,000",
            },
            {
                "organization": "Eversource Energy",
                "role": "Sustainability Program Manager",
                "match_score": 0.87,
                "career_page_url": "https://eversource.com/careers",
                "contact": "Mike Chen, Hiring Manager",
                "location": "Westwood, MA",
                "salary_range": "$75,000-$90,000",
            },
        ]

    def _calculate_match_confidence(self, matches: List[Dict[str, Any]]) -> float:
        """Calculate confidence from partner matches"""
        if not matches:
            return 0.0

        scores = [match.get("match_score", 0.5) for match in matches]
        return max(scores) if scores else 0.5

    # Routing methods
    def _route_initial_discovery(self, state: ClimateAgentState) -> str:
        """Route after initial discovery - bypass human review for simple interactions"""
        # Check if this is a simple greeting or basic interaction
        latest_message = ""
        if state.get("messages"):
            for msg in reversed(state["messages"]):
                if isinstance(msg, HumanMessage):
                    latest_message = msg.content.lower().strip()
                    break
        
        # Simple greetings should go directly to END to return response
        simple_greetings = ["hi", "hello", "hey", "sup", "yo", "howdy"]
        if latest_message in simple_greetings:
            logger.info(f"Simple greeting '{latest_message}' - bypassing human review")
            return "END"
        
        # Complex queries can still use human review if needed
        if state.get("needs_human_review"):
            return "human_review"
        return "analysis"

    def _route_after_discovery(self, state: ClimateAgentState) -> str:
        """Route after discovery phase"""
        incremental_findings = state.get("incremental_findings", [])
        if len(incremental_findings) < 2:
            return "analysis"
        return "human_review"

    def _route_after_analysis(self, state: ClimateAgentState) -> str:
        """Route after analysis phase"""
        if state.get("needs_human_review"):
            return "human_review"
        elif len(state.get("incremental_findings", [])) >= 3:
            return "partner_matching"
        else:
            return "confidence_assessment"

    def _route_after_confidence(self, state: ClimateAgentState) -> str:
        """Route after confidence assessment"""
        confidence = self._calculate_overall_confidence(state)
        confidence_threshold = state.get("confidence_threshold", 0.8)
        if confidence >= confidence_threshold:
            return "application_guidance"
        return "conversation_continuation"

    def _route_after_application(self, state: ClimateAgentState) -> str:
        """Route after application guidance"""
        if state.get("conversation_complete"):
            return "END"
        return "conversation_continuation"

    async def _route_conversation_flow(self, state: ClimateAgentState) -> str:
        """Route conversation flow based on state and human steering"""
        try:
            # Initialize counters if not present
            step_count = state.get("step_count", 0) + 1
            steering_count = state.get("human_steering_count", 0)

            # Update state with new counts
            state.update({"step_count": step_count, "human_steering_count": steering_count})

            # Check if conversation is complete
            if state.get("conversation_complete", False):
                logger.info("Conversation complete, ending workflow")
                return "END"

            # Check if we're waiting for human input
            if state.get("waiting_for_input", False):
                # If we have a human message, we can proceed
                has_human_input = False
                if state.get("messages"):
                    for msg in reversed(state["messages"]):
                        if isinstance(msg, HumanMessage):
                            has_human_input = True
                            break

                if not has_human_input:
                    logger.info("Waiting for human input before proceeding")
                    return "human_steering_point"

                # We have human input, clear waiting flag and proceed to analysis
                state["waiting_for_input"] = False
                return "incremental_analysis"

            # Check limits
            if step_count >= 10:  # Limit to 10 steps
                logger.warning(f"Max workflow steps (10) reached")
                state["conversation_complete"] = True
                return "END"

            if steering_count >= 3:  # Limit to 3 steering attempts
                logger.warning("Max human steering attempts (3) reached")
                state["conversation_complete"] = True
                return "END"

            # Check if we need human review
            if state.get("needs_human_review", False):
                state["human_steering_count"] = steering_count + 1
                state["waiting_for_input"] = True  # Set waiting flag
                return "human_steering_point" if steering_count < 2 else "END"

            # Check if we have enough information to proceed
            if self._has_sufficient_information(state):
                return "analysis"

            # Default to human steering if we need more information
            state["waiting_for_input"] = True  # Set waiting flag
            return "human_steering_point"

        except Exception as e:
            logger.error(f"Error in conversation routing: {e}")
            return "human_steering_point"  # Default to human steering on error


def create_climate_supervisor_workflow() -> ClimateSupervisorWorkflow:
    """Factory function to create enhanced climate supervisor workflow"""
    try:
        workflow = ClimateSupervisorWorkflow()
        logger.info("âœ… Enhanced climate supervisor workflow created successfully")
        return workflow
    except Exception as e:
        logger.error(f"Failed to create climate supervisor workflow: {e}")
        raise


# Create singleton instance for LangGraph export
_workflow_instance = None


def get_workflow_instance() -> ClimateSupervisorWorkflow:
    """Get or create singleton workflow instance"""
    global _workflow_instance
    if _workflow_instance is None:
        try:
            _workflow_instance = create_climate_supervisor_workflow()
        except Exception as e:
            logger.error(f"Error creating climate supervisor workflow instance: {e}")
            raise
    return _workflow_instance


# Export for LangGraph
climate_supervisor_graph = get_workflow_instance().graph
