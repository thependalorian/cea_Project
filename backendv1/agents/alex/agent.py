"""
Alex - Empathy & Emotional Support Specialist Agent

Following rule #3: Component documentation - Alex provides emotional support and empathy
Following rule #12: Complete code verification with proper error handling
Following rule #15: Include comprehensive error checks and logging

Enhanced with LLM-based reasoning instead of hardcoded keywords to avoid user misclassification.
Location: backendv1/agents/alex/agent.py
"""

import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime

from backendv1.agents.base.agent_base import AgentBase, AgentResponse, AgentContext
from backendv1.utils.logger import setup_logger

logger = setup_logger("alex_agent")


class AlexAgent(AgentBase):
    """
    Alex - Empathy & Emotional Support Specialist

    Enhanced with conversational incremental updates and LLM-based reasoning
    to avoid hardcoded keyword misclassification of users.
    """

    def __init__(self, name: str = "Alex", role: str = "empathy_specialist"):
        """Initialize Alex agent with empathy specialization"""
        super().__init__(agent_name=name, agent_type=role)
        logger.info(f"âœ… {name} agent initialized successfully")
        self.specializations = [
            "emotional_support",
            "career_anxiety",
            "confidence_building",
            "work_life_balance",
        ]

    def _load_prompts(self):
        """Load agent-specific prompts and templates"""
        self.system_prompt = """You are Alex, an empathy and emotional support specialist for climate career transitions.
        
Your role is to:
- Provide emotional support and validation
- Help users build confidence in their climate career journey
- Detect and respond to crisis situations with appropriate care
- Use conversational, incremental guidance rather than overwhelming information
- Focus on emotional well-being while maintaining career focus
        
Always be warm, understanding, and supportive while keeping conversations focused on climate career opportunities."""

        self.validation_prompts = {
            "stress": "I understand you're feeling stressed about your career transition. That's completely normal.",
            "confidence": "I can sense your enthusiasm about climate careers, which is wonderful!",
            "uncertainty": "It's natural to feel uncertain when exploring new paths. Let's take this step by step.",
            "frustration": "I hear your frustration, and it's valid. Career transitions can be challenging.",
        }

    def _load_tools(self):
        """Load and configure agent-specific tools"""
        self.available_tools = [
            "emotional_assessment",
            "crisis_detection",
            "empathy_workflow",
            "confidence_building",
            "validation_responses",
        ]

    def _setup_capabilities(self):
        """Set up agent-specific capabilities and configurations"""
        self.capabilities = {
            "emotional_support": True,
            "crisis_intervention": True,
            "confidence_building": True,
            "empathy_workflow": True,
            "llm_reasoning": True,
            "conversational_guidance": True,
        }

        # Set up LLM for emotional assessments
        try:
            from langchain_openai import ChatOpenAI

            self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)
        except Exception as e:
            logger.warning(f"Could not initialize LLM for Alex agent: {e}")
            self.llm = None

    async def process_message(self, message: str, context: AgentContext) -> AgentResponse:
        """
        Process user message with empathetic support and intelligent routing

        Uses LLM-based reasoning instead of keyword matching to avoid misclassification
        """
        try:
            logger.info(f"ðŸ¤— Alex processing empathetic support request")

            # Step 1: Assess emotional state using LLM reasoning (not keywords)
            emotional_state = await self._assess_emotional_state_with_llm(message, context)

            # Step 2: Provide immediate validation
            validation = self._provide_immediate_validation(emotional_state)

            # Step 3: Assess complexity using LLM reasoning
            complexity_score = await self._assess_complexity_with_llm(message, context)

            # Step 4: Route based on complexity and emotional needs
            if complexity_score >= 0.7:
                logger.info(
                    f"ðŸ”„ High complexity ({complexity_score:.2f}) - routing to empathy workflow"
                )
                return await self._handle_complex_emotional_support(
                    message, context, emotional_state
                )
            else:
                logger.info(
                    f"ðŸ’¬ Direct support ({complexity_score:.2f}) - providing immediate empathetic response"
                )
                return await self._provide_direct_empathetic_support(
                    message, context, emotional_state, validation
                )

        except Exception as e:
            logger.error(f"Error in Alex agent processing: {e}")
            return AgentResponse(
                content="I'm here to support you on your climate career journey. Let's take this one step at a time. What's on your mind?",
                confidence_score=0.6,
                sources=["Alex - Empathy Specialist"],
                next_actions=[
                    "Tell me more about what you're experiencing",
                    "Let's explore climate opportunities together",
                ],
            )

    async def _assess_emotional_state_with_llm(
        self, message: str, context: AgentContext
    ) -> Dict[str, Any]:
        """
        Assess user's emotional state using LLM reasoning instead of keyword matching

        This approach uses the LLM to understand emotional context, tone, and nuance
        rather than relying on hardcoded keywords that can misclassify users.
        """
        try:
            # Use LLM to analyze emotional state with structured output
            from langchain_core.prompts import ChatPromptTemplate
            from langchain_core.output_parsers import PydanticOutputParser
            from pydantic import BaseModel, Field
            from typing import Literal

            class EmotionalAssessment(BaseModel):
                primary_emotion: Literal[
                    "stress", "confidence", "frustration", "excitement", "uncertainty", "neutral"
                ] = Field(description="The primary emotional state detected in the message")
                intensity: float = Field(
                    description="Emotional intensity from 0.0 to 1.0", ge=0.0, le=1.0
                )
                support_needed: Literal["low", "moderate", "high"] = Field(
                    description="Level of emotional support needed"
                )
                career_readiness: float = Field(
                    description="User's readiness for career action from 0.0 to 1.0", ge=0.0, le=1.0
                )
                reasoning: str = Field(description="Brief explanation of the emotional assessment")

            parser = PydanticOutputParser(pydantic_object=EmotionalAssessment)

            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        """You are an expert emotional intelligence specialist analyzing user messages for climate career guidance.

Analyze the emotional state, tone, and context of the user's message. Consider:
- Explicit emotional expressions
- Implicit emotional indicators (tone, word choice, sentence structure)
- Career-related stress or confidence signals
- Readiness for taking action
- Need for emotional support

Avoid keyword matching - focus on understanding the full context and meaning.

{format_instructions}""",
                    ),
                    ("human", "User message: {message}"),
                ]
            )

            # Get LLM instance (assuming it's available in the agent)
            if hasattr(self, "llm") and self.llm:
                llm = self.llm
            else:
                # Fallback to a basic LLM if not available
                from langchain_openai import ChatOpenAI

                llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)

            chain = prompt | llm | parser

            assessment = await chain.ainvoke(
                {"message": message, "format_instructions": parser.get_format_instructions()}
            )

            return {
                "primary_emotion": assessment.primary_emotion,
                "intensity": assessment.intensity,
                "support_needed": assessment.support_needed,
                "career_readiness": assessment.career_readiness,
                "reasoning": assessment.reasoning,
                "assessment_method": "llm_reasoning",
            }

        except Exception as e:
            logger.warning(f"LLM emotional assessment failed, using fallback: {e}")

            # Fallback to a simple neutral assessment if LLM fails
            return {
                "primary_emotion": "neutral",
                "intensity": 0.5,
                "support_needed": "moderate",
                "career_readiness": 0.5,
                "reasoning": "Unable to assess emotional state, providing neutral support",
                "assessment_method": "fallback",
            }

    def _provide_immediate_validation(self, emotional_state: Dict[str, Any]) -> str:
        """Provide immediate emotional validation based on LLM assessment"""
        primary_emotion = emotional_state.get("primary_emotion", "neutral")
        reasoning = emotional_state.get("reasoning", "")

        validations = {
            "stress": f"I can sense you're feeling stressed about your climate career path, and that's completely understandable. {reasoning}",
            "frustration": f"It sounds like you're experiencing some frustration with your career direction, which is a natural part of the journey. {reasoning}",
            "confidence": f"I can sense your enthusiasm and confidence about climate careers, which is wonderful to see. {reasoning}",
            "excitement": f"Your excitement about climate opportunities is inspiring! {reasoning}",
            "uncertainty": f"It's natural to feel uncertain when exploring new career paths. {reasoning}",
            "neutral": f"I'm here to support you as you explore climate career opportunities. {reasoning}",
        }

        return validations.get(primary_emotion, validations["neutral"])

    async def _assess_complexity_with_llm(self, message: str, context: AgentContext) -> float:
        """
        Assess if complex emotional support workflow is needed using LLM reasoning

        This replaces keyword-based complexity detection with intelligent assessment
        of the user's emotional and situational complexity.
        """
        try:
            from langchain_core.prompts import ChatPromptTemplate
            from langchain_core.output_parsers import PydanticOutputParser
            from pydantic import BaseModel, Field

            class ComplexityAssessment(BaseModel):
                complexity_score: float = Field(
                    description="Complexity score from 0.0 to 1.0 indicating need for workflow support",
                    ge=0.0,
                    le=1.0,
                )
                factors: list[str] = Field(description="List of factors contributing to complexity")
                reasoning: str = Field(description="Brief explanation of complexity assessment")

            parser = PydanticOutputParser(pydantic_object=ComplexityAssessment)

            # Include conversation history context
            history_context = ""
            if context.conversation_history:
                recent_messages = context.conversation_history[-3:]
                history_context = f"\n\nRecent conversation context:\n" + "\n".join(
                    [str(msg) for msg in recent_messages]
                )

            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        """You are assessing the complexity of a user's emotional and career situation to determine if they need comprehensive workflow support.

Consider these factors for complexity:
- Multiple life challenges (career + personal)
- Deep emotional distress or mental health concerns
- Major life transitions or decisions
- Systemic barriers or discrimination
- Financial or family pressures
- Repeated patterns of struggle in conversation history

Score 0.0-0.3: Simple support needed
Score 0.4-0.6: Moderate complexity 
Score 0.7-1.0: High complexity requiring workflow support

{format_instructions}""",
                    ),
                    ("human", "Current message: {message}{history_context}"),
                ]
            )

            # Get LLM instance
            if hasattr(self, "llm") and self.llm:
                llm = self.llm
            else:
                from langchain_openai import ChatOpenAI

                llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)

            chain = prompt | llm | parser

            assessment = await chain.ainvoke(
                {
                    "message": message,
                    "history_context": history_context,
                    "format_instructions": parser.get_format_instructions(),
                }
            )

            logger.info(
                f"Complexity assessment: {assessment.complexity_score} - {assessment.reasoning}"
            )
            return assessment.complexity_score

        except Exception as e:
            logger.warning(f"LLM complexity assessment failed, using fallback: {e}")
            # Conservative fallback - assume moderate complexity
            return 0.5

    async def _handle_complex_emotional_support(
        self, message: str, context: AgentContext, emotional_state: Dict[str, Any]
    ) -> AgentResponse:
        """Handle complex emotional support using empathy workflow"""
        try:
            logger.info("ðŸ”„ Routing to empathy workflow for complex emotional support")

            # In production, this would invoke the empathy workflow
            # For now, provide comprehensive empathetic response

            validation = self._provide_immediate_validation(emotional_state)

            # Comprehensive support response
            support_content = f"""{validation}

Let me provide you with some immediate support and then we can explore how to move forward together.

**Immediate Support:**
- Your feelings are valid and many people experience similar challenges in career transitions
- Climate careers can feel overwhelming, but you don't have to navigate this alone
- We have a supportive community of climate professionals who understand your journey

**Next Steps Together:**
- I can connect you with a climate career mentor from our partner network
- We can explore opportunities that align with your values and reduce stress
- Our partners offer supportive work environments that prioritize employee wellbeing

Would you like me to help you connect with someone from our partner organizations who has been through a similar experience?"""

            return AgentResponse(
                content=support_content,
                confidence_score=0.8,
                sources=[
                    "Alex - Empathy Specialist",
                    "CEA Partner Network",
                    "Climate Professional Community",
                ],
                next_actions=[
                    "Connect with a climate career mentor",
                    "Explore supportive partner organizations",
                    "Join our climate professional support group",
                    "Get personalized emotional support resources",
                ],
                metadata={
                    "emotional_state": emotional_state,
                    "support_level": "comprehensive",
                    "workflow_used": "empathy_workflow",
                    "partner_connection_available": True,
                },
            )

        except Exception as e:
            logger.error(f"Error in complex emotional support: {e}")
            return await self._provide_direct_empathetic_support(
                message, context, emotional_state, "I'm here to support you."
            )

    async def _provide_direct_empathetic_support(
        self, message: str, context: AgentContext, emotional_state: Dict[str, Any], validation: str
    ) -> AgentResponse:
        """Provide direct empathetic support with incremental insights"""
        try:
            primary_emotion = emotional_state.get("primary_emotion", "neutral")
            career_readiness = emotional_state.get("career_readiness", 0.5)

            # Incremental insight based on emotional state
            if primary_emotion == "stress":
                insight = "Many successful climate professionals started their journey feeling uncertain. The key is taking small, manageable steps."
                next_actions = [
                    "Let's identify one small step you can take today",
                    "I can show you stress-free ways to explore climate careers",
                ]
            elif primary_emotion == "frustration":
                insight = "Frustration often signals that you're ready for change. Let's channel that energy into finding the right climate opportunity."
                next_actions = [
                    "Let's clarify what's most important to you in a climate career",
                    "I can help you find partners that match your values",
                ]
            elif primary_emotion == "confidence":
                insight = "Your confidence is a great foundation! Let's build on that momentum to find the perfect climate role."
                next_actions = [
                    "Let's explore opportunities that match your enthusiasm",
                    "I can connect you with partners looking for motivated candidates",
                ]
            else:
                insight = "Every climate career journey is unique. Let's find the path that feels right for you."
                next_actions = [
                    "Tell me more about what draws you to climate work",
                    "I can help you explore different climate career paths",
                ]

            # Partner-focused guidance
            partner_guidance = ""
            if career_readiness >= 0.6:
                partner_guidance = "\n\n**Partner Opportunities:**\nI can connect you with organizations in our network that prioritize employee support and meaningful climate impact. These partners understand the importance of work-life balance and professional growth."

            content = f"""{validation}

{insight}

{partner_guidance}

What aspect of climate careers would you like to explore together?"""

            return AgentResponse(
                content=content,
                confidence_score=min(0.9, 0.6 + (career_readiness * 0.3)),
                sources=["Alex - Empathy Specialist", "CEA Partner Network"],
                next_actions=next_actions,
                metadata={
                    "emotional_state": emotional_state,
                    "support_level": "direct",
                    "incremental_insight": insight,
                    "career_readiness": career_readiness,
                },
            )

        except Exception as e:
            logger.error(f"Error in direct empathetic support: {e}")
            return AgentResponse(
                content="I'm here to support you on your climate career journey. Let's take this one step at a time.",
                confidence_score=0.6,
                sources=["Alex - Empathy Specialist"],
                next_actions=[
                    "Tell me what's on your mind",
                    "Let's explore climate opportunities together",
                ],
            )

    def get_capabilities(self) -> Dict[str, Any]:
        """Get Alex's enhanced capabilities"""
        return {
            "primary_role": "Empathy & Emotional Support Specialist",
            "specializations": [
                "Career transition emotional support",
                "Climate career anxiety management",
                "Confidence building for job applications",
                "Work-life balance guidance",
                "Imposter syndrome support",
                "Stress management for career changes",
            ],
            "conversation_features": [
                "Immediate emotional validation",
                "Incremental support insights",
                "Complexity assessment for workflow routing",
                "Partner-focused emotional guidance",
            ],
            "integration_capabilities": [
                "Empathy workflow for complex scenarios",
                "Partner network connections for emotional support",
                "Climate professional mentorship matching",
                "Supportive work environment identification",
            ],
            "confidence_threshold": 0.7,
            "response_style": "empathetic_incremental",
        }
